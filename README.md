# Detecting Harmful Online Comments

![Build Status](https://img.shields.io/badge/build-passing-brightgreen)  
![License](https://img.shields.io/badge/license-MIT-blue)

## ğŸ“– Overview  
Fineâ€‘tuned BERT classifier to detect threats, insults, and hate speech in online comments, achieving **89.5% accuracy** and **89.2% F1â€‘score**.

## ğŸš€ Features  
- Preprocessing & tokenization with Huggingfaceâ€™s BERT tokenizer  
- Singleâ€‘label toxicity classification (toxic vs. nonâ€‘toxic)  
- Demo notebook for interactive exploration

## ğŸ—‚ï¸ Repository Structure  
```text
â”œâ”€â”€ data/  
â”œâ”€â”€ notebooks/  
â”œâ”€â”€ src/  
â”œâ”€â”€ slides/  
â”œâ”€â”€ requirements.txt  
â””â”€â”€ README.md
