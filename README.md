# Detecting Harmful Online Comments

![Build Status](https://img.shields.io/badge/build-passing-brightgreen)  
![License](https://img.shields.io/badge/license-MIT-blue)

## 📖 Overview  
Fine‑tuned BERT classifier to detect threats, insults, and hate speech in online comments, achieving **89.5% accuracy** and **89.2% F1‑score**.

## 🚀 Features  
- Preprocessing & tokenization with Huggingface’s BERT tokenizer  
- Single‑label toxicity classification (toxic vs. non‑toxic)  
- Demo notebook for interactive exploration

## 🗂️ Repository Structure  
```text
├── data/  
├── notebooks/  
├── src/  
├── slides/  
├── requirements.txt  
└── README.md
